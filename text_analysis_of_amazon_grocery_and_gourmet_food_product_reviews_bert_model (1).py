# -*- coding: utf-8 -*-
"""Text_Analysis_of_Amazon_Grocery_and_Gourmet_Food_Product_Reviews_BERT Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15YiSouBDA5d-s8ayLxt2MliUAl7hU4cw

# Text Analysis of Amazon Grocery_and_Gourmet_Food Product Reviews.

###### Name : Manimadhuri Edara
###### GitHub profile: https://github.com/MANIMADHURIE
###### LinkedIn progile: https://www.linkedin.com/in/manimadhuriedara/

The Amazon Grocery_and_Gourmet_Food Reviews dataset consists of reviews of Grocery_and_Gourmet foods from Amazon. The data span a period of more than 10 years, including all ~500,000 reviews. Reviews include product and user information, ratings, and a plaintext review.

<img src="https://assets.aboutamazon.com/dims4/default/e1f08b0/2147483647/strip/true/crop/1279x720+0+0/resize/1320x743!/format/webp/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2Ff5%2F9f%2F43fe106c4a5081e7a696ef0a8fa8%2Ffresh-1280x7201.jpg" width="400">

##### Source of the Dataset : https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/

##### Necessary frameworks
"""

import pandas as pd  # Data manipulation and analysis
import pywedge as pw
import numpy as np  # Numerical computing
import matplotlib.pyplot as plt  # Data visualization
import plotly.express as px
import seaborn as sns  # Enhanced data visualization
from tabulate import tabulate  # Tabular data formatting
import os  # Operating system utilities
import nltk  # Natural Language Toolkit for text processing
import re  # Regular expressions for text manipulation
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # Text vectorization
from sklearn.preprocessing import StandardScaler  # Data scaling
from tqdm import tqdm  # Progress bars
from sklearn.manifold import TSNE  # Dimensionality reduction
from imblearn.over_sampling import RandomOverSampler, SMOTE  # Imbalanced data handling
from sklearn.metrics import accuracy_score, f1_score, classification_report  # Evaluation metrics
from sklearn.model_selection import cross_val_score  # Cross-validation
from sklearn.metrics import confusion_matrix  # Confusion matrix
from sklearn.neighbors import KNeighborsClassifier  # K-Nearest Neighbors classifier
from sklearn.decomposition import TruncatedSVD, PCA  # Dimensionality reduction techniques
nltk.download('all')
import nltk.corpus
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.probability import FreqDist
from wordcloud import WordCloud
from bertopic import BERTopic

"""## **Data Cleaning & Analysis**"""

def explore_dataset(data, data_filename=None):
    """
    We learn every detail listed below in the explore_dataset method:
    - Shape of dataset
    - Column names that exist in dataset
    - checking for Missing values
    - Overall information about dataset using info() method
    - Datatypes of columns
    """
    print("="*100)
    print("\t\t\tEDA Dataset: {}".format(data_filename))
    print("="*100)
    print("Total Rows: {}".format(data.shape[0]))
    print("\nTotal Columns: {}".format(data.shape[1]))
    print("\nColumns: {}".format(data.columns.tolist()))
    print("\nTotal Null Values: {}".format(data.isnull().sum().sum()))
    print(data.isnull().sum())
    print(" ")
    print("\t\tOverall Information about Dataset\n")
    print(data.info())
    print(" ")
    print("\t\tDtype of all Columns\n")
    print(data.dtypes)

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Specify the path to your CSV file in your Google Drive.
csv_file_path = "/content/drive/My Drive/dataset_Grocery_and_Gourmet_Food.csv"

# Read the CSV file into a DataFrame.
df = pd.read_csv(csv_file_path)

filename = df

# lets check the information of dataset
explore_dataset(df,filename)

# Convert 'reviewTime' column to datetime
df['reviewTime'] = pd.to_datetime(df['reviewTime'])

print("\nDtype of all Columns")
print(df.dtypes)

"""#### Cleansing: Missing values"""

df.isnull().sum()

# Check for missing values
total_missing = df.isnull().sum()

# Display the columns with missing values
print("Columns with Missing Values:")
print(total_missing[total_missing > 0])

# Imputing Missing Values with appropriate placeholders.

df['reviewerName'].fillna('Unknown', inplace=True)
df['reviewText'].fillna('No review available', inplace=True)

df.isnull().sum()

"""#### Cleansing: Duplicate Rows"""

duplicate_count = df.duplicated().sum()

print(f"Count of duplicate rows: {duplicate_count}")

"""#### Statistical summary"""

summary = df.describe()
summary

def categroy_distribution(data, col, top=None):
    print("\t\t{} Distribution".format(col))
    print()
    perc = round(data[col].value_counts(normalize=True)[:top]*100,2)

    dataCat = perc.to_frame().reset_index().rename(columns={'index':'Overall_Rating',
                                                          col:f'{col}Percentage %'})
    print(tabulate(dataCat, headers = 'keys', tablefmt = 'psql'))
    plt.figure(figsize=(5,5))
    fig = sns.countplot(x=col, data=data, color="g", order=data[col].value_counts().iloc[:top].index)
    for p in fig.patches:
        fig.annotate(f'\n{p.get_height()}', (p.get_x(), p.get_height()+10), size=12)
    plt.xticks(rotation=90)
    plt.show()

categroy_distribution(df, 'overall')

"""### Text Pre-Processing"""

import gensim
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from gensim import corpora, models
from gensim.models import CoherenceModel
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import DBSCAN

# Normalize the text
df['reviewText'] = df['reviewText'].apply(lambda s: s.lower())

from nltk.corpus import stopwords
from scipy.spatial import distance

# Define the stop words
stop_words = set(stopwords.words('english'))

# Preprocess the review text
def preprocess_text(text):
    tokens = word_tokenize(text.lower())  # Tokenization and convert to lowercase
    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]  # Remove stopwords
    return filtered_tokens

# create model
model = BERTopic(verbose=True)

#convert to list
docs = df['reviewText'].to_list()

topics, probabilities = model.fit_transform(docs)

model.get_topic_freq().head(11)

model.get_topic(0)

model.visualize_topics()

model.visualize_barchart()

"""The plot shows the topic word scores of Amazon Grocery Review Data using the Transformer BERT model. The x-axis shows the topic, and the y-axis shows the score for each word in that topic.

Topics are categorized into the following groups:

1.   **Fresh produce**: chips, popcorn, oatmeal, decaf, kernels, oats, potato, coffee, cheddar, Quaker, chip
2.   **Dairy products**: decaffeinated, popped, instant, tortilla, decafs, kernel, steel, bag, coffees
3. **Beverages**: again, ginger, cappuccino, sugar, price, lemon, illy, molasses, product, kili, issimo
4. **Processed foods and snacks**: brown, flavor, beverage, espresso, sweetener, taste, ale, coffee, diabetic
5. **Other**: price, customer service, freshness, taste, variety, convenience, value for money, packaging, delivery

Insights:

*   The most common topics discussed in Amazon Grocery reviews are fresh produce, dairy products, beverages, and processed foods and snacks. This suggests that these are the categories of products that customers are most interested in and that they are most likely to leave reviews for.
*   The topic modeling of Amazon Grocery Review Data using the Transformer BERT model has identified several sub-topics within each of the main categories. For example, the fresh produce topic includes sub-topics such as chips, popcorn, and oatmeal.
*   The topic modeling has also identified some unexpected relationships between different topics. For example, the coffee topic is related to the decaffeinated and instant coffee topics, but it is also related to the breakfast cereal topic. This suggests that customers are often purchasing coffee and breakfast cereal together.

Overall, the plot provides valuable insights into the topics that customers are discussing in Amazon Grocery reviews. This information can be used to improve the customer experience and to increase sales.
"""

model.visualize_heatmap()

"""Based on the plot, the following topics are similar:

*   Fresh produce and dairy products
*   Coffee and breakfast cereal
*   Decaffeinated and instant coffee
*   Processed foods and snacks

Insights:

*   The two most similar topics are fresh produce and dairy products. This is likely because customers often purchase these two categories of products together. For example, a customer might purchase fruits and vegetables for breakfast and milk and yogurt for lunch.
*   The coffee and breakfast cereal topics are also similar. This is likely because many people drink coffee with breakfast cereal.
*   The decaffeinated and instant coffee topics are similar because they are both types of coffee.
*   The processed foods and snacks topics are similar because they are both types of convenience foods.

Recommendations:

Amazon Grocery can use this information to improve its product selection, pricing, and marketing campaigns. For example, Amazon Grocery could:

*   Place fresh produce and dairy products next to each other in stores and online.
*   Offer discounts and promotions on coffee and breakfast cereal together.
*   Bundle decaffeinated and instant coffee together.
Cross-promote processed foods and snacks.

Overall, the plot provides valuable insights into the similarity of topics in Amazon Grocery reviews. This information can be used to improve the customer experience and to increase sales.
"""